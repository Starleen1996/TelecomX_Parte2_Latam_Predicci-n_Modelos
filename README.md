# TelecomX_Parte2_Latam_Predicci-n_Modelos

## INTROCUCCI√ìN
La intenci√≥n de realizar el proyecto es establecer modelos de predicci√≥n de **Churn** de clientes de la compa√±ia **TelecomX_Latam** aplicando una estadistica descriptiva y aprendizaje automatico (Machine Learning). Por ende,  la compa√±ia quiere conocer que tipo de clientes podr√≠an permanecer o retirar los diferentes servicios que se ofrecen, para ello debemos establecer unas variables explicativas y la variable objetivo (respuesta) en nuestro modelo de Machine Learning. 

## Tabla de Contenido
* Descripci√≥n del proyecto
* Creaci√≥n del repositorio en Github
* Listado de Bibliotecas a utilizar para el desarrollo del proyecto
* Extracci√≥n del archivo tratado (CSV)
* Eliminaci√≥n de columnas irrelevantes
* Realizar el Encoding
* Verificaci√≥n de la Proporci√≥n de Cancelaci√≥n (Churn)
* Balanceo de Clases (opcional)
* Normalizaci√≥n o Estandarizaci√≥n (si es necesario)
* Correlaci√≥n y Selecci√≥n de Variables
* An√°lisis de Correlaci√≥n
* An√°lisis Dirigido
* Modelado Predictivo
* Separaci√≥n de Datos
* Creaci√≥n de Modelos
* Evaluaci√≥n de los Modelos
* Interpretaci√≥n y Conclusiones
* An√°lisis de la Importancia de las Variables
* Conclusi√≥n

1. **Descripci√≥n del Proyecto**
La compa√±ia quiere anticiparse a la problematica de cancelaci√≥n de servicios, para ello debemos analizar los datos historicos sobre nuestros clientes y servicios, posteriormente debemos establecer modelos de machine learning  para comparar su efectividad en la predicci√≥n de clientes (churn). Para ello vamos a establecer modelos como: **Baseline**, **Arbol de Decisiones**, **Random Forest** y comparar su rendimiento.

2. **Creaci√≥n del repositorio en Github**
Para el desarrollo del proyecto realizamos la creaci√≥n del repositorio en Github. donde se encontrar√° disponible el proyecto y ser usado libremente por cualquier persona que tenga interes. https://github.com/Starleen1996/TelecomX_Parte2_Latam_Predicci-n_Modelos.git

3. ** Listado de Bibliotecas a utilizar para el desarrollo del proyecto**
Para el desarrollo del proyecto realizamos el uso de diferentes bibliotecas Python entre ellas:
* import requests
* import json
* import pandas as pd
* import sklearn
* import pickle
* import numpy as np
* import seaborn as sns
* import matplotlib.pyplot as plt
* import warnings
* warnings.filterwarnings('ignore')
* import plotly.express as px
* import yellowbrick
* import DecisionTreeClassifier
* import train_test_split
* from sklearn.compose import make_column_transformer  # Este modulo ayuda a realizar una transformaci√≥n de columnas
* from sklearn.preprocessing import OneHotEncoder # Ayuda a realizar transformaci√≥n de 1 y 0
* from sklearn.model_selection import StratifiedKFold # Aseguramos que la proporci√≥n de cada clase se mantenga
* from sklearn.preprocessing import StandardScaler
* from sklearn.linear_model import LogisticRegression
* from sklearn.pipeline import Pipeline
* from sklearn.metrics import classification_report, confusion_matrix
* from sklearn.metrics import accuracy_score, confusion_matrix
* from imblearn.over_sampling import SMOTE
* from imblearn.pipeline import Pipeline as ImbPipeline


4. **Extracci√≥n del archivo tratado (CSV)**
Realizamos la extracci√≥n del archivo tratado (CSV), este ya se encuentra limpiado y normalizado con el fin de extraer las columnas que se encontraban en diccionarios, eliminar datos nullos y vacios, cambio del tipo de columnas entre otros.
url = 'https://raw.githubusercontent.com/Starleen1996/TelecomX_Parte2_Latam_Predicci-n_Modelos/refs/heads/main/df_clientes_LATAM.csv'

5. **Eliminaci√≥n de Columnas irrelevantes**
Vamos a realizar la eliminaci√≥n de la columna **ID_Cliente** ya que no aporta valor al an√°lisis o al modelo predictivo

6. **Realizar el Encoding**
En este paso realizamos la transformaci√≥n de las variables explicativas, excluyendo la variable de respuesta. para este paso primero hacemos la separaci√≥n de las variables explicativas y la variable de respuesta.

X = datos.drop('cliente_vigente', axis=1)
y= datos['cliente_vigente']

posteriormente realizamos la transformaci√≥n de los datos (Encodig) utilizando la biblioteca sklearn.compose y el modulo make_columns_transformer, sklearn.preprocessing import OneHotEncoder.
En la transformaci√≥n de datos, logramos que las variables categoricas queden de forma binaria (0 y 1), esto se hace con el procesamientos de los datos en nuestros modelos de machine learning no presenten errores o sesgos.

7. **Verificaci√≥n de la Proporci√≥n de Cancelaci√≥n (Churn)**
 Verificando la proporci√≥n de cancelaci√≥n vemos un desbalance en la variable (clientes vigentes), para ello utilizamos el metodo **datos.value_counts('cliente_vigente')**
0 = Clientes que siguen en la compa√±ia  (5174 Clientes)
1 = Clientes que se han retirado en la compa√±ia (1869 Clientes)
Con el fin de que ambas clases  queden con igual proporci√≥n de los datos vamos a realizar una estratificaci√≥n (balanceo) en nuestra variable objetivo o de respuesta.
8. **Balanceo de Clases (opcional)**
9. **Normalizaci√≥n o Estandarizaci√≥n (si es necesario)**
10. **Correlaci√≥n y Selecci√≥n de Variables**
Realizamos la correlaci√≥n entre las variables n√∫mericas, entre ellas la variable objetivo (respuesta) **Churn** para verificar el resultado respecto a las variables explicativas. Para ello realizamos un filtro de las variables tipo (int64', 'float64) y posteriormente calculamos la correlaci√≥n con el metodo (corr()), finalmente para tener una mejor visualizaci√≥n de las correlaciones, realizamos un grafico (Heatmap) con laa biblioteca Seaborn.
11. **An√°lisis Dirijido de Correlaci√≥n:**

N√∫mero de meses_contrato vs total_pagado_cliente: 0.825
Muy fuerte correlaci√≥n positiva.
Significa que cuanto m√°s meses tiene el cliente en contrato, mayor es el total pagado.
Es esperable: m√°s tiempo = m√°s facturaci√≥n.
    
N√∫mero de meses_contrato vs cliente_vigente: -0.352
Correlaci√≥n negativa moderada.
Sugiere que a mayor n√∫mero de meses en contrato, hay cierta tendencia a que el cliente ya no est√© vigente (abandone el servicio).
No es muy fuerte, pero hay relaci√≥n.

total_pagado_cliente vs cliente_vigente: -0.199
Correlaci√≥n negativa d√©bil.
Indica que los clientes que han pagado m√°s, tienden ligeramente a no estar vigentes, pero la relaci√≥n es d√©bil (casi cercana a 0).

**En Resumen:**

La variable m√°s fuerte es:
#_meses_contrato ‚Üî total_pagado_cliente (0.825).
Existe un patr√≥n de rotaci√≥n de clientes:
mientras m√°s tiempo y m√°s pagan, hay una ligera probabilidad de que ya no est√©n vigentes (correlaciones negativas con cliente_vigente).
Pero esas correlaciones negativas no son lo suficientemente fuertes como para sacar conclusiones absolutas; se deber√≠a complementar con otros an√°lisis.

12. **Modelado Predictivo:**
    
Modelos recomendados para este caso

* Regresi√≥n Log√≠stica:

Punto de partida cl√°sico para problemas de clasificaci√≥n binaria.

Te da interpretabilidad (puedes ver qu√© variable aumenta o disminuye la probabilidad de estar vigente).

Puede verse afectada por la multicolinealidad entre meses_contrato y total_pagado_cliente.

* √Årboles de Decisi√≥n:

No tienen problema con colinealidad.

F√°cil de interpretar en forma de reglas (ej: "si meses_contrato > X entonces...").

* Random Forest o Gradient Boosting (XGBoost, LightGBM, CatBoost):

Muy recomendados cuando quieres mayor precisi√≥n.

Manejan bien relaciones no lineales y colinealidad.

Random Forest ‚Üí bueno para empezar.

XGBoost/LightGBM ‚Üí mejor rendimiento si tienes m√°s datos.

* Redes Neuronales (opcional, si tienes muchos datos):

Podr√≠an aplicarse, pero en un dataset peque√±o o con pocas variables no aporta mucho m√°s que un modelo de boosting.+

13. **Separaci√≥n de Datos**
Realizamos la separaci√≥n de los datos para entrenamiento y prueba, lo recomendable es usar el 70/80 porciento para entrenamiento y 30/20 porciento para probar el modelo, para ellos utilizamos el modulo import train_test_split de la biblioteca sklearn.modelselection.

14 - 15 **Creaci√≥n y Evaluaci√≥n de modelos**

**Modelo Regresi√≥n Log√≠stico**
Uno de los modelos utilizados fue el de regresi√≥n log√≠stica, donde se evaluaron las variables explicativas y variables de respuesta.

**Resultados principales:**

Exactitud (Accuracy):

Entrenamiento: 0.95

Prueba: 0.77

‚ûù El modelo generaliza relativamente bien, aunque hay una ca√≠da de 0.95 ‚Üí 0.77, lo que indica cierto sobreajuste (el modelo aprende muy bien los datos de entrenamiento, pero pierde rendimiento con los de prueba).

Reporte de Clasificaci√≥n:

**Clase 0 (No Vigente):**

Precisi√≥n: 0.87

Recall: 0.81

F1-score: 0.84

‚ûù El modelo identifica bastante bien a los clientes No Vigentes, con buena precisi√≥n y recall.

**Clase 1 (Vigente):**

Precisi√≥n: 0.56

Recall: 0.66

F1-score: 0.61

‚ûù El desempe√±o es m√°s bajo en la clase Vigente, aunque el recall de 0.66 muestra que el modelo logra recuperar 2 de cada 3 clientes vigentes. La precisi√≥n baja (0.56) indica que se generan falsos positivos (se predicen vigentes clientes que no lo son).

**Matriz de Confusi√≥n:**

1258 clientes No Vigentes bien clasificados.

294 No Vigentes mal clasificados como Vigentes.

188 Vigentes mal clasificados como No Vigentes.

373 Vigentes bien clasificados.

‚ûù El modelo tiende a estar m√°s inclinado hacia predecir No Vigentes, aunque SMOTE ayud√≥ a balancear un poco (sin SMOTE seguramente la clase Vigente habr√≠a tenido un recall a√∫n m√°s bajo).

üîé Conclusiones sobre el modelo:

El balanceo con SMOTE ayud√≥ a mejorar el recall de la clase minoritaria (Vigente), aunque todav√≠a el rendimiento es desigual entre clases.

El accuracy general (0.77) es aceptable, pero se debe analizar con cuidado dado el desbalance original: el modelo sigue siendo mejor prediciendo la clase mayoritaria.

La Regresi√≥n Log√≠stica funciona como un modelo base que da buena interpretabilidad, pero puede que no capture relaciones complejas en tus datos.

El hecho de que el recall en "Vigente" sea mayor que la precisi√≥n significa que el modelo prefiere arriesgarse a clasificar clientes como Vigentes (aunque se equivoque), lo cual puede ser bueno si tu inter√©s es detectar clientes que se mantendr√°n activos y no perderlos.
