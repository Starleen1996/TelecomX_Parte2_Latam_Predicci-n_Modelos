# TelecomX_Parte2_Latam_Predicci-n_Modelos

## INTROCUCCI√ìN
La intenci√≥n de realizar el proyecto es establecer modelos de predicci√≥n de **Churn** de clientes de la compa√±ia **TelecomX_Latam** aplicando una estadistica descriptiva y aprendizaje automatico (Machine Learning). Por ende,  la compa√±ia quiere conocer que tipo de clientes podr√≠an permanecer o retirar los diferentes servicios que se ofrecen, para ello debemos establecer unas variables explicativas y la variable objetivo (respuesta) en nuestro modelo de Machine Learning. 

## Tabla de Contenido
* Descripci√≥n del proyecto
* Creaci√≥n del repositorio en Github
* Listado de Bibliotecas a utilizar para el desarrollo del proyecto
* Extracci√≥n del archivo tratado (CSV)
* Eliminaci√≥n de columnas irrelevantes
* Realizar el Encoding
* Verificaci√≥n de la Proporci√≥n de Cancelaci√≥n (Churn)
* Balanceo de Clases (opcional)
* Normalizaci√≥n o Estandarizaci√≥n (si es necesario)
* Correlaci√≥n y Selecci√≥n de Variables
* An√°lisis de Correlaci√≥n
* An√°lisis Dirigido
* Modelado Predictivo
* Separaci√≥n de Datos
* Creaci√≥n de Modelos
* Evaluaci√≥n de los Modelos
* Interpretaci√≥n y Conclusiones
* An√°lisis de la Importancia de las Variables


1. **Descripci√≥n del Proyecto**
La compa√±ia quiere anticiparse a la problematica de cancelaci√≥n de servicios, para ello debemos analizar los datos historicos sobre nuestros clientes y servicios, posteriormente debemos establecer modelos de machine learning  para comparar su efectividad en la predicci√≥n de clientes (churn). Para ello vamos a establecer modelos como: **Baseline**, **Arbol de Decisiones**, **Random Forest** y comparar su rendimiento.

2. **Creaci√≥n del repositorio en Github**
Para el desarrollo del proyecto realizamos la creaci√≥n del repositorio en Github. donde se encontrar√° disponible el proyecto y ser usado libremente por cualquier persona que tenga interes. https://github.com/Starleen1996/TelecomX_Parte2_Latam_Predicci-n_Modelos.git

3. ** Listado de Bibliotecas a utilizar para el desarrollo del proyecto**
Para el desarrollo del proyecto realizamos el uso de diferentes bibliotecas Python entre ellas:
* import requests
* import json
* import pandas as pd
* import sklearn
* import pickle
* import numpy as np
* import seaborn as sns
* import matplotlib.pyplot as plt
* import warnings
* warnings.filterwarnings('ignore')
* import plotly.express as px
* import yellowbrick
* import DecisionTreeClassifier
* import train_test_split
* from sklearn.compose import make_column_transformer  # Este modulo ayuda a realizar una transformaci√≥n de columnas
* from sklearn.preprocessing import OneHotEncoder # Ayuda a realizar transformaci√≥n de 1 y 0
* from sklearn.model_selection import StratifiedKFold # Aseguramos que la proporci√≥n de cada clase se mantenga
* from sklearn.preprocessing import StandardScaler
* from sklearn.linear_model import LogisticRegression
* from sklearn.pipeline import Pipeline
* from sklearn.metrics import classification_report, confusion_matrix
* from sklearn.metrics import accuracy_score, confusion_matrix
* from imblearn.over_sampling import SMOTE
* from imblearn.pipeline import Pipeline as ImbPipeline
* from sklearn.dummy import DummyClassifier
* from sklearn.neighbors import KNeighborsClassifier


4. **Extracci√≥n del archivo tratado (CSV)**
Realizamos la extracci√≥n del archivo tratado (CSV), este ya se encuentra limpiado y normalizado con el fin de extraer las columnas que se encontraban en diccionarios, eliminar datos nullos y vacios, cambio del tipo de columnas entre otros.
url = 'https://raw.githubusercontent.com/Starleen1996/TelecomX_Parte2_Latam_Predicci-n_Modelos/refs/heads/main/df_clientes_LATAM.csv'

5. **Eliminaci√≥n de Columnas irrelevantes**
Vamos a realizar la eliminaci√≥n de la columna **ID_Cliente** ya que no aporta valor al an√°lisis o al modelo predictivo

6. **Realizar el Encoding**
En este paso realizamos la transformaci√≥n de las variables explicativas, excluyendo la variable de respuesta. para este paso primero hacemos la separaci√≥n de las variables explicativas y la variable de respuesta.

X = datos.drop('cliente_vigente', axis=1)
y= datos['cliente_vigente']

posteriormente realizamos la transformaci√≥n de los datos (Encodig) utilizando la biblioteca sklearn.compose y el modulo make_columns_transformer, sklearn.preprocessing import OneHotEncoder.
En la transformaci√≥n de datos, logramos que las variables categoricas queden de forma binaria (0 y 1), esto se hace con el procesamientos de los datos en nuestros modelos de machine learning no presenten errores o sesgos.

7. **Verificaci√≥n de la Proporci√≥n de Cancelaci√≥n (Churn)**
 Verificando la proporci√≥n de cancelaci√≥n vemos un desbalance en la variable (clientes vigentes), para ello utilizamos el metodo **datos.value_counts('cliente_vigente')**
0 = Clientes que siguen en la compa√±ia  (5174 Clientes)
1 = Clientes que se han retirado en la compa√±ia (1869 Clientes)
Con el fin de que ambas clases  queden con igual proporci√≥n de los datos vamos a realizar una estratificaci√≥n (balanceo) en nuestra variable objetivo o de respuesta.
8. **Balanceo de Clases (opcional)**
9. **Normalizaci√≥n o Estandarizaci√≥n (si es necesario)**
10. **Correlaci√≥n y Selecci√≥n de Variables**
Realizamos la correlaci√≥n entre las variables n√∫mericas, entre ellas la variable objetivo (respuesta) **Churn** para verificar el resultado respecto a las variables explicativas. Para ello realizamos un filtro de las variables tipo (int64', 'float64) y posteriormente calculamos la correlaci√≥n con el metodo (corr()), finalmente para tener una mejor visualizaci√≥n de las correlaciones, realizamos un grafico (Heatmap) con laa biblioteca Seaborn.
11. **An√°lisis Dirijido de Correlaci√≥n:**

N√∫mero de meses_contrato vs total_pagado_cliente: 0.825
Muy fuerte correlaci√≥n positiva.
Significa que cuanto m√°s meses tiene el cliente en contrato, mayor es el total pagado.
Es esperable: m√°s tiempo = m√°s facturaci√≥n.
    
N√∫mero de meses_contrato vs cliente_vigente: -0.352
Correlaci√≥n negativa moderada.
Sugiere que a mayor n√∫mero de meses en contrato, hay cierta tendencia a que el cliente ya no est√© vigente (abandone el servicio).
No es muy fuerte, pero hay relaci√≥n.

total_pagado_cliente vs cliente_vigente: -0.199
Correlaci√≥n negativa d√©bil.
Indica que los clientes que han pagado m√°s, tienden ligeramente a no estar vigentes, pero la relaci√≥n es d√©bil (casi cercana a 0).

**En Resumen:**

La variable m√°s fuerte es:
#_meses_contrato ‚Üî total_pagado_cliente (0.825).
Existe un patr√≥n de rotaci√≥n de clientes:
mientras m√°s tiempo y m√°s pagan, hay una ligera probabilidad de que ya no est√©n vigentes (correlaciones negativas con cliente_vigente).
Pero esas correlaciones negativas no son lo suficientemente fuertes como para sacar conclusiones absolutas; se deber√≠a complementar con otros an√°lisis.

12. **Modelado Predictivo:**
    
Modelos recomendados para este caso

* Regresi√≥n Log√≠stica:

Punto de partida cl√°sico para problemas de clasificaci√≥n binaria.

Te da interpretabilidad (puedes ver qu√© variable aumenta o disminuye la probabilidad de estar vigente).

Puede verse afectada por la multicolinealidad entre meses_contrato y total_pagado_cliente.

* √Årboles de Decisi√≥n:

No tienen problema con colinealidad.

F√°cil de interpretar en forma de reglas (ej: "si meses_contrato > X entonces...").

* Random Forest o Gradient Boosting (XGBoost, LightGBM, CatBoost):

Muy recomendados cuando quieres mayor precisi√≥n.

Manejan bien relaciones no lineales y colinealidad.

Random Forest ‚Üí bueno para empezar.

XGBoost/LightGBM ‚Üí mejor rendimiento si tienes m√°s datos.

* Redes Neuronales (opcional, si tienes muchos datos):

Podr√≠an aplicarse, pero en un dataset peque√±o o con pocas variables no aporta mucho m√°s que un modelo de boosting.+

13. **Separaci√≥n de Datos**
Realizamos la separaci√≥n de los datos para entrenamiento y prueba, lo recomendable es usar el 70/80 porciento para entrenamiento y 30/20 porciento para probar el modelo, para ellos utilizamos el modulo import train_test_split de la biblioteca sklearn.modelselection.

14 - 15 **Creaci√≥n y Evaluaci√≥n de modelos**

## Modelo de referencia (BaseLine)
Modelo Dummy
Un modelo base es muy importante para definir un criterio de comparaci√≥n para modelos m√°s complejos. En esta etapa, crea un modelo base con el DummyClassifier y encuentra la tasa de acierto con el m√©todo score.

El modelo m√°s simple de clasificar los datos es simplemente utilizar un algoritmo que asigna todas las clasificaciones a la clase que tiene mayor frecuencia. Este algoritmo sirve como un criterio de comparaci√≥n para identificar si los otros modelos tienen un rendimiento mejor que la clasificaci√≥n m√°s simple posible.

**Modelo Baseline (DummyClassifier):**
#Obtuvo un score de 0.7345 aproximadamente.
#Este modelo sirve √∫nicamente como punto de referencia, ya que no aprende patrones reales de los datos, sino que sigue una estrategia trivial (por ejemplo, predecir siempre la clase mayoritaria).

## Modelo √Årbol de Decisi√≥n
Para la clasificaci√≥n de clientes (Churn), vamos a usar el modelo **+√Årbol de Decisiones** ya que es uno de los modelos recomendados para predecir datos y clasificarlos.
Justificaci√≥n Normalizaci√≥n: Para este modelo aunque no es necesario normalizar nuestros datos, decid√≠ hacerlo ya que en el an√°lisis de correlaci√≥n no pude determinar una fuerza positiva o negativa sobre la variable objetivo (churn).

El modelo de √°rbol de decisi√≥n es muy utilizado debido a su alta explicabilidad y procesamiento r√°pido, manteniendo un rendimiento bastante interesante.
Se basa en decisiones simples tomadas por el algoritmo, separando los datos mediante comparaciones de menor y mayor en los valores de las columnas de la base de datos.

**Modelo_arbol = DecisionTreeClassifier(max_depth=5, random_state=42)**
Evaluamos el modelo con datos de prueba con una profundidad de 5 y estado de aleatoriedad de 42
modelo_arbol.fit(X_train, y_train)
modelo_arbol.score(X_test,y_test)

**Score en datos de prueba (X_test): 0.7931**

**Score en datos de entrenamiento (X_train): 0.8079**

**üìä Resumen**

Mejora frente al baseline: Antes, tu √Årbol sin restricciones estaba cerca de 0.73 en test, ahora subi√≥ a ~0.79, lo cual indica que limitar la profundidad ayud√≥ al modelo a generalizar mejor.

Generalizaci√≥n adecuada: La diferencia entre entrenamiento (0.8079) y prueba (0.7931) es muy peque√±a (~0.015). üëâ Esto es una se√±al positiva: el modelo no est√° sobreajustado y mantiene un desempe√±o bastante estable en datos no vistos.

Impacto del hiperpar√°metro max_depth: Al limitar la profundidad a 5, el modelo evit√≥ memorizar los datos de entrenamiento y logr√≥ un balance entre sesgo y varianza.

**‚úÖ Conclusi√≥n**

El ajuste de profundidad mejor√≥ la capacidad de generalizaci√≥n del √Årbol de Decisi√≥n.

El modelo ahora supera claramente al baseline y tiene un buen equilibrio entre entrenamiento y prueba.

A√∫n se podr√≠a explorar m√°s hiperpar√°metros (criterio de divisi√≥n, n√∫mero m√≠nimo de muestras por hoja, etc.), pero ya se evidencia un avance significativo.

## Modelo Regresi√≥n Log√≠stico
**Resumen del Modelo Regresi√≥n Log√≠stica - Sin Balanceo**
üìä Resultados obtenidos

Accuracy (Exactitud) en prueba (X_test, y_test) Esto significa que, de todos los clientes en tu conjunto de prueba, el modelo predice correctamente si se quedan o se van en un 79.7% de los casos.

Accuracy (Exactitud) en entrenamiento (X_train, y_train) En los datos con los que el modelo aprendi√≥, acierta en un 80.9% de los casos.

üîé **Interpretaci√≥n**

Generalizaci√≥n: Los resultados de entrenamiento (80.9%) y prueba (79.7%) son muy similares ‚Üí el modelo no est√° sobreajustado (no memoriz√≥ los datos) y generaliza bien a nuevos clientes.

Buen desempe√±o inicial: Acertar casi en 8 de cada 10 clientes es un desempe√±o razonable para un primer modelo.

Limitaciones de Accuracy: En churn, muchas veces el problema est√° desbalanceado (es decir, hay m√°s clientes que permanecen que los que se retiran). El accuracy puede ser enga√±oso, porque el modelo podr√≠a estar prediciendo bien a los que permanecen y fallando en los que se van, que suelen ser los m√°s importantes para la empresa.

‚úÖ **En conclusi√≥n:** Tu modelo logra ~80% de aciertos y generaliza bien, lo cual es un buen punto de partida. El siguiente paso es profundizar en m√©tricas como recall para clientes que abandonan, ya que para la empresa es m√°s costoso no detectar a un cliente que se va que equivocarse en un cliente que se queda.

1.**Matriz de confusi√≥n**

[[1382 170]

[ 258 303]]

1382 (Verdaderos Negativos, VN): Clientes que realmente NO se fueron (0) y el modelo predijo correctamente que se quedan.

170 (Falsos Positivos, FP): Clientes que el modelo predijo que se iban, pero en realidad se quedaron.

258 (Falsos Negativos, FN): Clientes que realmente se fueron, pero el modelo dijo que se quedaban.

303 (Verdaderos Positivos, VP): Clientes que realmente se fueron y el modelo lo predijo correctamente.

üìä **2. Reporte de clasificaci√≥n**

Para clase 0 (clientes que permanecen):

Precision = 0.84: El 84% de los que predijo como "no se van" realmente no se fueron.

Recall = 0.89: Detecta bien a los que se quedan (89%).

F1-Score = 0.87: Buen balance entre precisi√≥n y recall. üìå El modelo es bastante s√≥lido para identificar clientes que se quedan.

Para clase 1 (clientes que se van = churn):

Precision = 0.64: De todos los que el modelo predijo que se iban, solo el 64% realmente se fue.

Recall = 0.54: Solo detecta al 54% de los clientes que efectivamente se fueron.

F1-Score = 0.59: D√©bil en comparaci√≥n con la clase 0. üìå Aqu√≠ est√° el problema: el modelo no est√° capturando bien a los clientes que hacen churn.

**üìä3. M√©tricas generales**

Accuracy (exactitud) = 0.80: El modelo acierta en el 80% de los casos. ‚ö†Ô∏è Pero este n√∫mero est√° sesgado porque hay muchos m√°s clientes que se quedan (clase 0) que los que se van (clase 1).

Macro avg (0.73 en F1): Promedio simple entre ambas clases (muestra que el modelo es m√°s d√©bil en la clase 1).

Weighted avg (0.79 en F1): Promedio ponderado seg√∫n la cantidad de ejemplos, est√° dominado por la clase 0.

**Conclusi√≥n para la empresa de telecomunicaciones:**

El modelo es bueno detectando qui√©nes se quedan (clase 0).

Pero es regular detectando qui√©nes se van (clase 1, churn) ‚Üí solo identifica al 54% de ellos.

En t√©rminos de negocio: üîπ Puedes confiar bastante en los clientes que el modelo dice que se quedar√°n. üîπ Pero deber√≠as mejorar la sensibilidad (recall) para no perder clientes que realmente se van.

## Modelo Regresi√≥n Log√≠stico con Balanceo
üîç**Interpretaci√≥n**

El modelo ya mejor√≥ bastante el recall de la clase 1 (79%) gracias a SMOTE ‚úÖ.

Esto significa que ahora detecta a la mayor√≠a de los clientes que abandonan (lo que pediste en el punto 1).

Pero hay un costo: la precisi√≥n para clase 1 baj√≥ a 0.51, lo que implica m√°s falsos positivos (clientes que el modelo cree que se van, pero en realidad no).

**Modelo KNN - SIN BALANCEO**
El algoritmo KNN se basa en el c√°lculo de la distancia entre los registros de la base de datos y busca elementos que est√©n cerca unos de otros (vecinos) para tomar la decisi√≥n de clasificaci√≥n.

Debido a que utiliza c√°lculos de distancia, este algoritmo est√° influenciado por la escala de las variables, y por eso es necesario realizar una transformaci√≥n en los datos antes de utilizar este m√©todo.

**2. Reporte de clasificaci√≥n**

Para clase 0 (clientes que permanecen):

Precision = 0.83: El 83% de los que predijo como "no se van" realmente no se fueron.

Recall = 0.84: Detecta bien a los que se quedan (84%).

F1-Score = 0.83: Buen balance entre precisi√≥n y recall. üìå El modelo es bastante s√≥lido para identificar clientes que se quedan.

Para clase 1 (clientes que se van = churn):

Precision = 0.53: De todos los que el modelo predijo que se iban, solo el 53% realmente se fue.

Recall = 0.51: Solo detecta al 51% de los clientes que efectivamente se fueron.

F1-Score = 0.52: D√©bil en comparaci√≥n con la clase 0. üìå Aqu√≠ est√° el problema: el modelo no est√° capturando bien a los clientes que hacen churn.

# Conclusiones Exactitud de los Modelos:
Resultados reportados:

Modelo Dummy (baseline): 0.7345

√Årbol de Decisiones: 0.7931

KNN: 0.7515

Regresi√≥n Log√≠stica (balanceada): 0.7463

üîé **Conclusiones principales**:

Comparaci√≥n con el modelo Dummy

El modelo Dummy sirve como referencia (predice lo m√°s frecuente o al azar).

Todos los modelos superan la exactitud del Dummy, lo cual indica que s√≠ est√°n aprendiendo patrones reales en los datos.

√Årbol de Decisiones ‚Üí Mejor exactitud (0.7931)

Es el modelo con mejor desempe√±o global en t√©rminos de exactitud.

Sugiere que los datos pueden tener relaciones no lineales y jer√°rquicas que el √°rbol captura mejor que KNN o la regresi√≥n log√≠stica.

KNN (0.7515) vs. Regresi√≥n Log√≠stica (0.7463 balanceada)

Ambos tienen un rendimiento similar, aunque el KNN ligeramente mejor.

El hecho de que la Regresi√≥n Log√≠stica balanceada est√© cerca al KNN indica que el desbalance de clases s√≠ afecta al dataset, y balancear ayuda a no perder sensibilidad hacia la clase minoritaria (churn).

Importancia del balanceo

Aunque la regresi√≥n balanceada no tiene la mayor exactitud, su fortaleza est√° en mejorar el recall de los clientes churn (clase 1).

La exactitud por s√≠ sola puede ser enga√±osa en datasets desbalanceados: un modelo puede tener buena exactitud pero ser malo prediciendo churn.

üìù **Conclusi√≥n final exactitud**:

El modelo Dummy alcanza una exactitud del 73.4%, lo que representa nuestra l√≠nea base. Todos los modelos superan este valor, confirmando que aprenden patrones √∫tiles. El √Årbol de Decisiones se posiciona como el mejor clasificador en t√©rminos de exactitud (79.3%), lo que indica que logra capturar relaciones complejas en los datos. Por su parte, KNN (75.1%) y la Regresi√≥n Log√≠stica balanceada (74.6%) tienen un rendimiento similar, aunque la regresi√≥n balanceada aporta la ventaja de mejorar la detecci√≥n de clientes en riesgo de churn gracias al ajuste frente al desbalance de clases. En conclusi√≥n, el √Årbol de Decisiones es el m√°s preciso globalmente, pero la Regresi√≥n Log√≠stica balanceada puede ser preferida si el objetivo principal es mejorar la sensibilidad en la predicci√≥n de clientes que se van.

# Conclusiones del Recall
üìå Conclusiones del recall por modelo:

**Modelo Dummy (0.0000)**

El modelo no logra identificar ning√∫n cliente que hace churn (1).

Esto confirma que el modelo dummy no es √∫til como predictor, solo sirve como referencia de base.

**√Årbol de Decisiones (0.5294)**

Logra identificar un poco m√°s de la mitad de los clientes que hacen churn.

Aunque es un avance respecto al dummy, a√∫n deja escapar casi la mitad de los clientes que realmente abandonan.

Puede estar sobreajustando o priorizando otras m√©tricas (como exactitud) en lugar de la sensibilidad.

**KNN (0.5080)**

Tiene un rendimiento muy similar al √°rbol de decisiones en t√©rminos de recall.

Esto sugiere que KNN tampoco logra capturar con suficiente eficacia los casos minoritarios de churn, posiblemente por la distribuci√≥n de clases desbalanceada.

**Regresi√≥n Log√≠stica Balanceada (0.7914)**

Es el modelo que mejor logra identificar a los clientes que abandonan.

Con casi un 80% de recall, se convierte en el m√°s prometedor si la prioridad es detectar churn, aunque podr√≠a sacrificar algo de precisi√≥n en las predicciones.

Esto confirma que aplicar t√©cnicas de balanceo de clases es clave para este problema.

‚úÖ Conclusi√≥n general: El modelo de regresi√≥n log√≠stica balanceado es el m√°s adecuado si el objetivo del negocio es maximizar la detecci√≥n de clientes en riesgo de abandono, ya que ofrece un recall muy superior. En contraste, √°rbol de decisiones y KNN se comportan de forma similar pero insuficiente, y el modelo dummy es completamente ineficaz.

**Grafico Exactitud Modelos:**

![Gr√°fico de exactitud](exactitud_modelos.png)
![Gr√°fico de Recall](recall_modelos.png)

16. **An√°lisis de la Importancia de las Variables:**

**Regresi√≥n Log√≠stica Balanceada:**
La ventaja de este modelo es que es interpretable:

Cada variable tiene un coeficiente (peso) ‚Üí indica c√≥mo cambia la probabilidad de cancelaci√≥n.

El signo del coeficiente:

(+) ‚Üí aumenta la probabilidad de churn.

(-) ‚Üí reduce la probabilidad de churn.

La magnitud absoluta ‚Üí indica la importancia relativa de la variable.

**KNN:**
KNN no tiene coeficientes, pero puedes investigar las variables con:

An√°lisis de distancias ‚Üí ver cu√°les variables m√°s contribuyen a diferenciar clientes que cancelan vs. los que no.

Feature importance v√≠a permutaci√≥n:

Se mide c√≥mo cambia el desempe√±o del modelo si "rompes" (permutas) una variable.

Si el recall baja mucho, esa variable es clave.

**√Årbol de Decisiones:**
Aqu√≠ es mucho m√°s visual:
El √°rbol aprende umbrales de decisi√≥n (ejemplo: "si el cliente tiene m√°s de 6 meses ‚Üí menos probabilidad de churn").
Puedes ver la importancia de variables directamente del modelo.

## Agradecimientos ü§ù

Quiero agradecer a Oracle y Alura LATAM por proporcionar las bases y el material necesarios para la realizaci√≥n de este proyecto, y por su alianza que hace posible este programa de capacitaci√≥n para el desarrollo del futuro en tecnolog√≠a.

![Alura LATAM](https://github.com/user-attachments/assets/92a155ab-bcbb-41c6-8bbc-a0e8f552eb0f) ![Oracle](https://github.com/user-attachments/assets/f399257d-d637-44be-809e-4bac2232fe25)

![ONE](https://github.com/user-attachments/assets/368ff23a-e3f2-4f08-a987-0f736996779c)

**Desarrollador del Proyecto:**
Realizado por: Starleen Gaviria Medina, Estudiante de Alura Latam, Ciencia de datos.

www.linkedin.com/in/starleen-gaviria-sig
